{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bihar Part: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # used for handling the dataset\n",
    "import numpy as np #used for handling numbers/scientific computing\n",
    "import matplotlib.pyplot as plt #used for plotting the datapoints\n",
    "import seaborn as sb #used for statistical data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\Sem_3\\\\ML_Project\\\\ahs-woman-1\\\\AHS_Woman_10_Bihar\\\\AHS_Woman_10_Bihar_Part_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing the dataset into 'raw_data' variable \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSem_3\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mML_Project\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mahs-woman-1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAHS_Woman_10_Bihar\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAHS_Woman_10_Bihar_Part_2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    572\u001b[0m     dialect,\n\u001b[0;32m    573\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    583\u001b[0m )\n\u001b[0;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1038\u001b[0m     )\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\Anaconda_Data\\envs\\Ellicium\\lib\\site-packages\\pandas\\io\\common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\Sem_3\\\\ML_Project\\\\ahs-woman-1\\\\AHS_Woman_10_Bihar\\\\AHS_Woman_10_Bihar_Part_2.csv'"
     ]
    }
   ],
   "source": [
    "# importing the dataset into 'raw_data' variable \n",
    "raw_data = pd.read_csv(r'F:\\Sem_3\\ML_Project\\ahs-woman-1\\AHS_Woman_10_Bihar\\AHS_Woman_10_Bihar_Part_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the type of raw_data \n",
    "type(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'shape' gives us the contents of dataset i.e., rows/entries/records/tuples = 866736\n",
    "#                                                columns/features/attributes/variables = 202\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the attributes in the dataset is\n",
    "list(raw_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'info' to get a concise summary of the dataframe\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view some basic statistical details like percentile, mean, std of dataframe(data)\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Wrangling\n",
    "* Preprocessing On Columns(data_cols)\n",
    "* Preprocessing On Rows(data_rows)\n",
    "* Dropping Uncessary Features\n",
    "* Resetting the Indexes\n",
    "* Rearranging the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the features that are needed\n",
    "data_cols = raw_data[['mother_age_when_baby_was_born','outcome_pregnancy','fp_method_used',\n",
    "                      'symptoms_pertaining_illness','diagnosed_for','regular_treatment','chew',\n",
    "                      'smoke','alcohol','drinking_water_source','kitchen_availability',\n",
    "                      'is_washing_machine','is_bicycle','is_scooter','is_sewing_machine',\n",
    "                      'ever_conceived','no_of_times_conceived','age_at_first_conception',\n",
    "                      'delivered_any_baby']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'shape' gives us the contents of dataset i.e., rows/entries/records/tuples = 1048575 \n",
    "#                                                columns/features/attributes/variables = 19\n",
    "data_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'info' to get a concise summary of the dataframe\n",
    "data_cols.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to view some basic statistical details like percentile, mean, std of dataframe(data)\n",
    "data_cols.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'isnull' detects the missing values and 'sum' returns the total count of null tuples for each attribute/column\n",
    "data_cols.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing missing values from dataset(axis = 0 states for rows and 'any' states for any NA attribute in dataset)\n",
    "data_rows = data_cols.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resetting the indexes\n",
    "data_rows.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rows.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_rows.drop('outcome_pregnancy', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['outcome_pregnancy'] = pd.DataFrame(data_rows['outcome_pregnancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pregnancy_details.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pregnancy_details = pregnancy_details.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pregnancy_details = pregnancy_details.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregnancy_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the output(without indexes) of dataframe(data_rows) to csv file named as \"pregnancy_details\"\n",
    "#pregnancy_details.to_csv(r'F:\\Sem_3\\ML_Project\\preg\\Cleaned_Data\\Bihar_Part2_Cleaned.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # 2. Correlations for the Pregnancy Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix():\n",
    "        \n",
    "    # For computing pairwise correlation of columns, excluding NA/null values\n",
    "    correlation = pregnancy_details.corr(method='pearson')\n",
    "    correlation\n",
    "    f = plt.figure(figsize=(10, 10))\n",
    "    plt.matshow(pregnancy_details.corr(), fignum=f.number)\n",
    "    plt.xticks(range(pregnancy_details.shape[1]), pregnancy_details.columns, fontsize=14, rotation=90)\n",
    "    plt.yticks(range(pregnancy_details.shape[1]), pregnancy_details.columns, fontsize=14)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    #plt.title('Correlation Matrix', fontsize=16);\n",
    "    plt.savefig(r'F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\1.png')\n",
    "    return correlation\n",
    "corr_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "* Pairplots\n",
    "* Boxplots\n",
    "* Barplots\n",
    "* Violinplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "class EDA():\n",
    "    \n",
    "    def pairplots():\n",
    "        sb.pairplot(pregnancy_details)\n",
    "        sb.set_style('darkgrid')\n",
    "\n",
    "    def boxplots():\n",
    "         for c in pregnancy_details.columns[1:]:\n",
    "            pregnancy_details.boxplot(c,by='outcome_pregnancy',figsize=(8,4),fontsize=14,grid=True)\n",
    "            plt.title(\"{}\\n\".format(c),fontsize=16)\n",
    "            plt.xlabel(\"Pregnancy Outcome\", fontsize=16)\n",
    "            plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\box.png\")\n",
    "\n",
    "    def count_barplots():\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='chew',data=pregnancy_details)\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to consumption of tobacco\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(['Pan with tobacco','Pan without tobacco','Gutka/Pan masala with tobacco',\n",
    "                    'Gutka/Pan masala without tobacco','Tobacco only','Ex–Chewer','Never chewed',\n",
    "                    'Not known'],loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\1.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='drinking_water_source',data=pregnancy_details,orient='v')\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to source of drinking water\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(['Piped water into dwelling/yard/plot','Public tap/standpipe','Hand pump', \n",
    "                    'Tube well or Borehole', 'Protected dug well', 'Unprotected dug well', \n",
    "                    'Tanker /truck/Cart with Surface watersmall tank', 'Surface water', \n",
    "                    'other sources'],loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\2.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='kitchen_availability',data=pregnancy_details)\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to availability of kitchen\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(['Cooking inside the house:Has kitchen','Does not have kitchen',\n",
    "                    'Cooking outside house:Has kitchen','Does not have kitchen',\n",
    "                    'No cooking'], loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\3.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='regular_treatment',data=pregnancy_details)\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to the treament taken\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(['Not Regularly','Regularly','No Treatment'], loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\4.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='no_of_times_conceived',data=pregnancy_details)\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to the number of times conceived\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\5.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='is_sewing_machine',data=pregnancy_details)\n",
    "        plt.title(\"Bar chart of outcome of pregnancy compared to use of sewing machine\", fontsize=17)\n",
    "        plt.xlabel(\"Count\", fontsize=15)\n",
    "        plt.ylabel(\"Outcome Of Pregnancy\", fontsize=15)\n",
    "        plt.legend(['Uses Sewing Machine','Does not use Sewing Machine'],loc=1)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\6.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='mother_age_when_baby_was_born',data=pregnancy_details)\n",
    "        plt.xlabel('Count',fontsize=15)\n",
    "        plt.ylabel('Outcome Of Pregnancy',fontsize=15)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\7.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='symptoms_pertaining_illness',data=pregnancy_details)\n",
    "        plt.xlabel('Count',fontsize=15)\n",
    "        plt.ylabel('Outcome Of Pregnancy',fontsize=15)\n",
    "        plt.legend(['Diseases of respiratory system','Diseases of cardiovascular system','Diseases of the central nervous  system','Diseases of   musculo-skeletal system','Diseases of gastrointestinal system','Diseases of genito urinary system','Skin diseases','Goitre','Elephantiasis','Others','Asymptomatic','Eye Problem/diseases','ENT problems/diseases','Mouth and Dental Problems','Others','No Symptoms of chronic diseases'])\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\8.png\")\n",
    "        \n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='is_scooter',data=pregnancy_details)\n",
    "        plt.xlabel('Count',fontsize=15)\n",
    "        plt.ylabel('Outcome Of Pregnancy',fontsize=15)\n",
    "        plt.legend(['Uses Scooter','Does not use Scooter'])\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\9.png\")\n",
    "        \n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='is_bicycle',data=pregnancy_details)\n",
    "        plt.xlabel('Count',fontsize=15)\n",
    "        plt.ylabel('Outcome Of Pregnancy',fontsize=15)\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\10.png\")\n",
    "\n",
    "        plt.figure(figsize=(13,6))\n",
    "        sb.set_style('darkgrid')\n",
    "        sb.countplot(y='outcome_pregnancy',hue='diagnosed_for',data=pregnancy_details)\n",
    "        plt.xlabel('Count',fontsize=15)\n",
    "        plt.ylabel('Outcome Of Pregnancy',fontsize=15)\n",
    "        plt.legend()\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\11.png\")\n",
    "        \n",
    "    def violinplots():\n",
    "        sb.catplot(x=\"fp_method_used\",y=\"outcome_pregnancy\",legend=True,data=pregnancy_details,kind=\"violin\")\n",
    "        \n",
    "        sb.catplot(x=\"symptoms_pertaining_illness\",y=\"outcome_pregnancy\",legend=True,data=pregnancy_details,kind=\"violin\")\n",
    "        \n",
    "        sb.catplot(x=\"regular_treatment\",y=\"outcome_pregnancy\",legend=True,data=pregnancy_details,kind=\"violin\")\n",
    "        \n",
    "        sb.catplot(x=\"kitchen_availability\",y=\"outcome_pregnancy\",legend=True,data=pregnancy_details,kind=\"violin\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA.violinplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling and Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score\n",
    "* Classification Accuracy is what we usually mean, when we use the term accuracy. It is the ratio of number of correct predictions to the total number of input samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Printing accuracy classification score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "* Confusion Matrix as the name suggests gives us a matrix as output and describes the complete performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Computing confusion matrix to evaluate the accuracy of a classification\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "* Used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a text report showing the main classification metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "* Mean Squared Error(MSE) is quite similar to Mean Absolute Error, the only difference being that MSE takes the average of the square of the difference between the original values and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints Mean squared error regression loss\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pregnancy_details.drop('outcome_pregnancy', axis=1)\n",
    "y = pregnancy_details['outcome_pregnancy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'x' consists of all the data except class label(outcome_pregnancy)\n",
    "### 'y' contains only class lable column i.e., outcome_pregnancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset content into random train and test subsets\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "class logisticRegression():\n",
    "    lor = LogisticRegression()\n",
    "    lor.fit(X_train,y_train)\n",
    "    yp_lr_train = lor.predict(X_train)\n",
    "    yp_lr_test = lor.predict(X_test)\n",
    "    \n",
    "    def training():\n",
    "        yp_lr_train = logisticRegression.yp_lr_train\n",
    "        print(\"Accuracy of logistic regression for training data:\",accuracy_score(y_train,yp_lr_train))\n",
    "        print(\"\\nClassification report of logistic regression for training data :\\n\\n\",classification_report(y_train,yp_lr_train))\n",
    "        print(\"Confusion_matrix of logistic regression for training data:\\n\",confusion_matrix(y_train,yp_lr_train))\n",
    "        print('\\nMean_squared_error of logistic regression for training data:',mean_squared_error(y_train,yp_lr_train))\n",
    "\n",
    "    def testing():\n",
    "        yp_lr_test = logisticRegression.yp_lr_test\n",
    "        print(\"Accuracy of logistic regression for testing data:\",accuracy_score(y_test,yp_lr_test))\n",
    "        print('\\nClassification of logistic regression for testing data:\\n\\n',classification_report(y_test,yp_lr_test))\n",
    "        print(\"Confusion_matrix of logistic regression for testing data:\\n\",confusion_matrix(y_test,yp_lr_test))\n",
    "        print('Mean_squared_error of logistic regression for testing data:\\n',mean_squared_error(y_test,yp_lr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2: Support Vector Machines(SVM)\n",
    "* Kernel.1 = Linear\n",
    "* Kernel.2 = Sigmoid\n",
    "* Kernel.3 = Radial Basis Function(RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel.1 = Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "class svc_linear():\n",
    "    \n",
    "    lin_svc = svm.SVC(kernel='linear')\n",
    "\n",
    "    lin_svc.fit(X_train,y_train)\n",
    "    yp_svm_lin_train = lin_svc.predict(X_train)\n",
    "    yp_svm_lin_test = lin_svc.predict(X_test)\n",
    "\n",
    "    def training():\n",
    "        yp_svm_lin_train = svc_linear.yp_svm_lin_train\n",
    "        print('Accuracy of Linear-SVM for training data:',accuracy_score(y_train,yp_svm_lin_train))\n",
    "        print('\\nClassification Report of Linear-SVM for training data:\\n\\n',classification_report(y_train,yp_svm_lin_train))\n",
    "        print('Confusion_matrix of Linear-SVM for training data:\\n',confusion_matrix(y_train,yp_svm_lin_train))\n",
    "        print('\\nMean_squared_error of Linear-SVM for training data:',mean_squared_error(y_train,yp_svm_lin_train))\n",
    "\n",
    "    def testing():\n",
    "        yp_svm_lin_test = svc_linear.yp_svm_lin_test\n",
    "        print('Accuracy of Linear-SVM for testing data:',accuracy_score(y_test,yp_svm_lin_test))\n",
    "        print('\\nClassification Report of Linear-SVM for testing data:\\n\\n',classification_report(y_test,yp_svm_lin_test))\n",
    "        print('Confusion_matrix of Linear-SVM for testing data:\\n',confusion_matrix(y_test,yp_svm_lin_test))\n",
    "        print('\\nMean_squared_error of Linear-SVM for testing data:',mean_squared_error(y_test,yp_svm_lin_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel.2 = Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svc_sigmoid():\n",
    "    sig_svc = svm.SVC(kernel='sigmoid')      \n",
    "    sig_svc.fit(X_train,y_train)\n",
    "    yp_svm_sig_train = sig_svc.predict(X_train)\n",
    "    yp_svm_sig_test = sig_svc.predict(X_test)\n",
    "    \n",
    "    def training():\n",
    "        yp_svm_sig_train = svc_sigmoid.yp_svm_sig_train\n",
    "        print('Accuracy of Sigmoid-SVM for training data:',accuracy_score(y_train,yp_svm_sig_train))\n",
    "        print('\\nClassification Report of Sigmoid-SVM for training data:\\n\\n',classification_report(y_train,yp_svm_sig_train))\n",
    "        print('Confusion_matrix of Sigmoid-SVM for training data:\\n',confusion_matrix(y_train,yp_svm_sig_train))\n",
    "        print('\\nMean_squared_error of Sigmoid-SVM for training data:',mean_squared_error(y_train,yp_svm_sig_train))\n",
    "\n",
    "    def testing():\n",
    "        yp_svm_sig_test = svc_sigmoid.yp_svm_sig_test\n",
    "        print('Accuracy of Sigmoid-SVM for testing data:',accuracy_score(y_test,yp_svm_sig_test))\n",
    "        print('\\nClassification Report of Sigmoid-SVM for testing data:\\n\\n',classification_report(y_test,yp_svm_sig_test))\n",
    "        print('Confusion_matrix of Sigmoid-SVM for testing data:\\n',confusion_matrix(y_test,yp_svm_sig_test))\n",
    "        print('\\nMean_squared_error of Sigmoid-SVM for testing data:',mean_squared_error(y_test,yp_svm_sig_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel.2 = Radial Basis Function(RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class svc_rbf():\n",
    "    rad_svc = svm.SVC(kernel='rbf')      \n",
    "    rad_svc.fit(X_train,y_train)\n",
    "    yp_svm_rad_train = rad_svc.predict(X_train)\n",
    "    yp_svm_rad_test = rad_svc.predict(X_test)\n",
    "    \n",
    "    def training():\n",
    "        yp_svm_rad_train = svc_rbf.yp_svm_rad_train\n",
    "        print('Accuracy of RBF-SVM for training data:',accuracy_score(y_train,yp_svm_rad_train))\n",
    "        print('\\nClassification Report of RBF-SVM for training data:\\n\\n',classification_report(y_train,yp_svm_rad_train))\n",
    "        print('Confusion_matrix of RBF-SVM for training data:\\n',confusion_matrix(y_train,yp_svm_rad_train))\n",
    "        print('\\nMean_squared_error of RBF-SVM for training data:',mean_squared_error(y_train,yp_svm_rad_train))\n",
    "\n",
    "    def testing():\n",
    "        yp_svm_rad_test = svc_rbf.yp_svm_rad_test\n",
    "        print('Accuracy of RBF-SVM for testing data:',accuracy_score(y_test,yp_svm_rad_test))\n",
    "        print('\\nClassification Report of RBF-SVM for testing data:\\n\\n',classification_report(y_test,yp_svm_rad_test))\n",
    "        print('Confusion_matrix of RBF-SVM for testing data:\\n',confusion_matrix(y_test,yp_svm_rad_test))\n",
    "        print('\\nMean_squared_error of RBF-SVM for testing data:',mean_squared_error(y_test,yp_svm_rad_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "class decisionTree():\n",
    "    dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "    dt.fit(X_train,y_train)\n",
    "    yp_dt_train = dt.predict(X_train)\n",
    "    yp_dt_test = dt.predict(X_test)\n",
    "\n",
    "    def training():\n",
    "        yp_dt_train = decisionTree.yp_dt_train\n",
    "        print('Accuracy of Decision-Tree for training data:',accuracy_score(y_train,yp_dt_train))\n",
    "        print('\\nClassification Report of Decision Tree for training data:\\n\\n',classification_report(y_train,yp_dt_train))\n",
    "        print('Confusion_matrix of Decision-Tree for training data:\\n',confusion_matrix(y_train,yp_dt_train))\n",
    "        print('\\nMean_squared_error of Decision-Treefor training data:',mean_squared_error(y_train,yp_dt_train))\n",
    "\n",
    "    def testing():\n",
    "        yp_dt_test = decisionTree.yp_dt_test \n",
    "        print('Accuracy of Decision-Tree for testing data:',accuracy_score(y_test,yp_dt_test))\n",
    "        print('\\nClassification of Decision-Tree for testing data:\\n\\n',classification_report(y_test,yp_dt_test)) \n",
    "        print('Classification of Decision-Tree for testing data:\\n',confusion_matrix(y_test,yp_dt_test))\n",
    "        print('\\nMean_squared_error of Decision-Tree for testing data:',mean_squared_error(y_test,yp_dt_test))\n",
    "        \n",
    "    def DT_plot():\n",
    "        dot_data = tree.export_graphviz(decisionTree.dt, out_file=None,max_depth=5, filled=True, rounded=True, special_characters=True)  \n",
    "        graph = graphviz.Source(dot_data)  \n",
    "        #graph.save(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\dt.png\")\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-4: k-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class KNN(): \n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    yp_knn_train = knn.predict(X_train)\n",
    "    yp_knn_test = knn.predict(X_test)\n",
    "    \n",
    "    def knn_plot():\n",
    "        error_rate = []\n",
    "        for i in range(1,10):\n",
    "\n",
    "            knn = KNeighborsClassifier(n_neighbors=i)\n",
    "            knn.fit(X_train,y_train)\n",
    "            pred_i = knn.predict(X_test)\n",
    "            error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "        # Plot for representing the exact value of 'K' to be considered\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.plot(range(1,10),error_rate,color='g', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "        plt.title('Error Rate vs. K Value')\n",
    "        plt.xlabel('K')\n",
    "        plt.ylabel('Error Rate')\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\knn_elbow.png\")\n",
    "\n",
    "   \n",
    "    def training():\n",
    "        yp_knn_train = KNN.yp_knn_train\n",
    "        print('Accuracy of K-Nearest Neighbor for training data:',accuracy_score(y_train,yp_knn_train))\n",
    "        print('Classification Report of K-Nearest Neighbor for training data:\\n\\n',classification_report(y_train,yp_knn_train))\n",
    "        print('Confusion_matrix of K-Nearest Neighbor for training data:\\n',confusion_matrix(y_train,yp_knn_train))\n",
    "        print('\\nMean_squared_error of K-Nearest Neighbor for training data:',mean_squared_error(y_train,yp_knn_train))\n",
    "\n",
    "        \n",
    "    def testing():\n",
    "        yp_knn_test = KNN.yp_knn_test\n",
    "        print('Accuracy of K-Nearest Neighbor for testing data:',accuracy_score(y_test,yp_knn_test))\n",
    "        print('\\nClassification Report of K-Nearest Neighbor for testing data:\\n\\n',classification_report(y_test,yp_knn_test))\n",
    "        print('Confusion_matrix of K-Nearest Neighbor for testing data:\\n',confusion_matrix(y_test,yp_knn_test)) \n",
    "        print('\\nMean_squared_error of K-Nearest Neighbor for testing data:',mean_squared_error(y_test,yp_knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-5: Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class naive_bayes():\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(X_train,y_train)\n",
    "    yp_nb_train = NB.predict(X_train)\n",
    "    yp_nb_test = NB.predict(X_test)\n",
    "\n",
    "    def training():\n",
    "        yp_nb_train = naive_bayes.yp_nb_train\n",
    "        print('Accuracy of Naive Bayes for training data:',accuracy_score(y_train,yp_nb_train))\n",
    "        print('\\nClassification Report of Naive Bayes for training data:\\n\\n',classification_report(y_train,yp_nb_train))\n",
    "        print('Confusion_matrix of Naive Bayes for training data:\\n',confusion_matrix(y_train,yp_nb_train))\n",
    "        print('\\nMean_squared_error of Naive Bayes for training data:',mean_squared_error(y_train,yp_nb_train))\n",
    "\n",
    "        \n",
    "    def testing():\n",
    "        yp_nb_test = naive_bayes.yp_nb_test\n",
    "        print('Accuracy of Naive Bayes for testing data:',accuracy_score(y_test,yp_nb_test))\n",
    "        print('\\nClassification Report of Naive Bayes for testing data:\\n\\n',classification_report(y_test,yp_nb_test))\n",
    "        print('Confusion_matrix of Naive Bayes for testing data:\\n',confusion_matrix(y_test,yp_nb_test))\n",
    "        print('\\nMean_squared_error of Naive Bayes for testing data:',mean_squared_error(y_test,yp_nb_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Principle Component Analysis(PCA) \n",
    "* Forward Feature Selection(Using Random-Forest)\n",
    "* Backward Feature Selection(Using Random-Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "class dimensionality_reduction():\n",
    "    x = pregnancy_details.drop('outcome_pregnancy',axis=1)\n",
    "    y = pregnancy_details['outcome_pregnancy']\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 0)\n",
    "    print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "    print('Testing dataset shape:', X_test.shape, y_test.shape)\n",
    "        \n",
    "    rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "        \n",
    "    def PCA():\n",
    "        pca_data = pregnancy_details.drop('outcome_pregnancy', axis=1) \n",
    "        cols = list(pca_data.columns)\n",
    "        \n",
    "        # Standardizing data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(pca_data)\n",
    "        scl_data = scaler.transform(pca_data)\n",
    "        scl_data = pd.DataFrame(data=scl_data)\n",
    "        \n",
    "        # Applying PCA on standardized data\n",
    "        pca = PCA(n_components=14)\n",
    "        pca.fit(scl_data)\n",
    "        px = np.arange(1, 15, step=1)\n",
    "        py = np.cumsum(pca.explained_variance_ratio_) \n",
    "        \n",
    "        # Plotting Elbow to get the no. of components to be considered \n",
    "        plt.figure(figsize=(13,6))\n",
    "        plt.ylim(0.0,1.1)\n",
    "        plt.plot(px,py,color='g', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.xticks(np.arange(0, 15, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "        plt.ylabel('Cumulative variance (%)')\n",
    "        plt.title('The number of components needed to explain variance')\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\pca_elbow.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        #X is projected on the first principal components previously extracted from a training set\n",
    "        reduced_pca_data = pca.transform(scl_data)\n",
    "\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        ax = Axes3D(fig, elev=-150, azim=110)\n",
    "        ax.scatter(reduced_pca_data[:,0],reduced_pca_data[:,1],reduced_pca_data[:,2],edgecolor='k', s=60, depthshade = True)\n",
    "        ax.set_title(\"First three PCA directions\")\n",
    "        ax.set_xlabel(\"1st eigenvector\")\n",
    "        ax.w_xaxis.set_ticklabels([])\n",
    "        ax.set_ylabel(\"2nd eigenvector\")\n",
    "        ax.w_yaxis.set_ticklabels([])\n",
    "        ax.set_zlabel(\"3rd eigenvector\")\n",
    "        ax.w_zaxis.set_ticklabels([])\n",
    "        plt.savefig(r\"F:\\Sem_3\\ML_Project\\preg\\Visualizations\\Bihar\\Part_2\\pca.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        print('PCA Columns:\\n',cols)\n",
    "        print('\\nScaled Data Type:\\n',type(scl_data))\n",
    "        print('\\nVariance:\\n',pca.explained_variance_)\n",
    "        print('\\nVariance Ratios:\\n',pca.explained_variance_ratio_)\n",
    "        \n",
    "    def ffs():\n",
    "        sfs1 = sfs(dimensionality_reduction.rf,k_features=4,forward=True,floating=False,verbose=2,scoring='accuracy',cv=5)\n",
    "        sfs1 = sfs1.fit(dimensionality_reduction.X_train,dimensionality_reduction.y_train)\n",
    "        feat_cols = list(sfs1.k_feature_idx_)\n",
    "        \n",
    "        print('\\nBest Features according to Forward Feature Selection are:\\n',sfs1.k_feature_names_)\n",
    "        print('\\nScore:',sfs1.k_score_)\n",
    "        \n",
    "    \n",
    "    def bfs():\n",
    "        bfs1 = sfs(dimensionality_reduction.rf,k_features=17,forward=False,floating=False,verbose=2,scoring='accuracy',cv=5)\n",
    "        bfs1 = bfs1.fit(dimensionality_reduction.X_train,dimensionality_reduction.y_train)\n",
    "        feat_cols = list(bfs1.k_feature_idx_)\n",
    "        \n",
    "        print('Best Feature according to Backward Feature Selection are:\\n',bfs1.k_feature_names_)\n",
    "        print('\\nScore:',bfs1.k_score_)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
